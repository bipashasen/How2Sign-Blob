{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b693b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import lmdb\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from collections import namedtuple\n",
    "\n",
    "import custom_datasets as cds\n",
    "\n",
    "from dataset import ImageFileDataset, CodeRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2d918286",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp VQVAE2/dataset.py .\n",
    "!cp VQVAE2/custom_datasets.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bffe4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset path exists: True\n",
      "lmdb path exists: True\n",
      "labels path exists: True\n"
     ]
    }
   ],
   "source": [
    "paths = {'dataset':'How2Sign-Keypoints', 'lmdb': 'VQVAE2/codes'}\n",
    "paths['labels'] = paths['dataset']+'/Labels'\n",
    "\n",
    "for key in paths:\n",
    "    print(f'{key} path exists: {os.path.exists(paths[key])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f1df981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003760 items in lmdb database\n",
      "listing labels directory:\n",
      "['how2sign_train.csv', 'how2sign_realigned_test.csv', 'how2sign_test.csv', 'how2sign_realigned_train.csv', 'how2sign_val.csv', 'how2sign_realigned_val.csv']\n"
     ]
    }
   ],
   "source": [
    "env = lmdb.open(\n",
    "        paths['lmdb'],\n",
    "        max_readers=32,\n",
    "        readonly=True,\n",
    "        lock=False,\n",
    "        readahead=False,\n",
    "        meminit=False,\n",
    "    )\n",
    "\n",
    "with env.begin(write=False) as txn:\n",
    "    lmdb_length = int(txn.get('length'.encode('utf-8')).decode('utf-8'))\n",
    "    \n",
    "    print(f'{lmdb_length} items in lmdb database')\n",
    "\n",
    "print(f'listing labels directory:\\n{os.listdir(paths[\"labels\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eda45e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31165 rows in labels (before dicting up)\n",
      "31165 rows in labels (after dicting up)\n",
      "\n",
      "['VIDEO_ID', 'VIDEO_NAME', 'SENTENCE_ID', 'SENTENCE_NAME', 'START', 'END', 'SENTENCE']\n",
      "\n",
      "1. --7E2sU6zP4_10-5-rgb_front\tAnd I call them decorative elements because basically all they're meant to do is to enrich and color the page.\n",
      "2. --7E2sU6zP4_11-5-rgb_front\tSo they don't really have much of a symbolic meaning other than maybe life is richer, life is beautiful, but they've become so beautifully stylized and so you find them in different illuminative being rendered in very different ways.\n",
      "3. --7E2sU6zP4_12-5-rgb_front\tNow this is very, this is actually an insert of a kind of an envelope for stationary, and this is a very Italian design.\n",
      "4. --7E2sU6zP4_13-5-rgb_front\tThis is all the you know, take off on the idea of the acanthus leaf.\n",
      "5. --7E2sU6zP4_5-5-rgb_front\tIt's almost has a feathery like posture to it.\n",
      "6. --7E2sU6zP4_6-5-rgb_front\tAnd so, it's used in architecture as a decorative element in architecture on columns and so on, and it's also used a great deal in illumination.\n",
      "7. --7E2sU6zP4_7-5-rgb_front\tAnd so what's happened with the idea of acanthus leaf, is that it has is taken on all these different creative looks.\n",
      "8. --7E2sU6zP4_8-5-rgb_front\tAnd it has been wildly colored so you can look at some an acanthus leaf and you can start with the idea of a black and white drawing.\n",
      "9. --7E2sU6zP4_9-5-rgb_front\tHere, actually, I have some samples of traced acanthus leaves from different illuminated manuscripts.\n",
      "10. --8pSDeC-fg_0-5-rgb_front\tHi.\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(paths['labels'], 'how2sign_train.csv')) as r:\n",
    "    labels = r.read().splitlines()\n",
    "          \n",
    "heading = labels[0].split()\n",
    "labels = [x.split('\\t') for x in labels[1:]]\n",
    "heading2index = {x:i for i, x in enumerate(heading)}\n",
    "\n",
    "print(f'{len(labels)} rows in labels (before dicting up)')\n",
    "\n",
    "labels = {\n",
    "    x[heading2index['SENTENCE_NAME']]: [\n",
    "        x[heading2index['SENTENCE']], \n",
    "        x[heading2index['START']],\n",
    "        x[heading2index['END']]\n",
    "    ] for x in labels}\n",
    "sentence_names = [x for x in labels]\n",
    "\n",
    "print(f'{len(labels)} rows in labels (after dicting up)')\n",
    "print()\n",
    "print(heading)\n",
    "print()\n",
    "for i in range(10):\n",
    "    index = sentence_names[i]\n",
    "    print(f'{i+1}. {index}\\t{labels[index][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9b9009f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_mapper = {}\n",
    "\n",
    "index_found = 0\n",
    "\n",
    "with env.begin(write=False) as txn:\n",
    "    for i in range(lmdb_length):\n",
    "        key = str(i).encode('utf-8')\n",
    "\n",
    "        row = pickle.loads(txn.get(key))\n",
    "        \n",
    "        labels_mapper[row.filename] = {\n",
    "            'top': row.top,\n",
    "            'bottom': row.bottom\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0e093ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 30\n",
    "\n",
    "labels_condensed = {}\n",
    "labels_indices = {}\n",
    "\n",
    "for key in sorted(labels_mapper.keys(), key=lambda x: int(x.split('_')[-1])):\n",
    "    sentence_name, index = key.rsplit('_', 1)\n",
    "    sentence_name = sentence_name.replace('_right', '')\n",
    "    index = int(index)\n",
    "    if sentence_name in labels_condensed:\n",
    "        labels_condensed[sentence_name].append(labels_mapper[key])\n",
    "        labels_indices[sentence_name].append(index)\n",
    "    else:\n",
    "        labels_condensed[sentence_name] = [labels_mapper[key]]\n",
    "        labels_indices[sentence_name] = [index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bcc3ff97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7250 common out of 7250\n",
      "example key: dIhOvhzskUg_6-8-rgb_front\n",
      "\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275]\n"
     ]
    }
   ],
   "source": [
    "common = len(set(labels_condensed.keys()).intersection(set(labels.keys())))\n",
    "\n",
    "print(f'{common} common out of {len(set(labels_condensed.keys()))}')\n",
    "\n",
    "k = list(labels_condensed.keys())[1]\n",
    "print(f'example key: {k}')\n",
    "\n",
    "print()\n",
    "print(labels_indices[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "05a56e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserted: 7249: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7250/7250 [01:46<00:00, 68.31it/s]\n"
     ]
    }
   ],
   "source": [
    "map_size = 100 * 1024 * 1024 * 1024\n",
    "\n",
    "lmdb_env = lmdb.open('video_codes', map_size=map_size)\n",
    "\n",
    "CodeRowVideos = namedtuple('CodeRowVideos', ['code', 'labels', 'indices', 'filename'])\n",
    "\n",
    "with lmdb_env.begin(write=True) as txn:\n",
    "    pbar = tqdm(labels_condensed.keys())\n",
    "    \n",
    "    for index, key in enumerate(pbar):\n",
    "        row = CodeRowVideos(code=labels_condensed[key], labels=labels[key], indices=labels_indices[key], filename=key)\n",
    "    \n",
    "        txn.put(str(index).encode('utf-8'), pickle.dumps(row))\n",
    "        pbar.set_description(f'inserted: {index}')\n",
    "\n",
    "    txn.put('length'.encode('utf-8'), str(index).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053dc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp process_data_for_pixelsnail.ipynb /home2/bipasha31/python_scripts/CurrentWork/SLP/utils"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
